{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6191 images belonging to 41 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = \"data_1/train\"\n",
    "VALIDATION_DIR = \"data_1/test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1507 images belonging to 41 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        target_size=(128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "                                input_tensor=Input(shape=(128, 128, 3)))\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "last_output = pre_trained_model.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 64, 64, 32)           864       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 64, 64, 32)           128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 64, 64, 32)           0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 64, 64, 32)           288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 64, 64, 32)           128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 64, 64, 32)           0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 64, 64, 16)           512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 64, 64, 16)           64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 64, 64, 96)           1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 64, 64, 96)           384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 64, 64, 96)           0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 65, 65, 96)           0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 32, 32, 96)           864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 32, 32, 96)           384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 32, 32, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 32, 32, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 32, 32, 24)           96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 32, 32, 144)          3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 32, 32, 144)          576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 32, 32, 144)          0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 32, 32, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 32, 32, 144)          576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 32, 32, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 32, 32, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 32, 32, 24)           96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 32, 32, 24)           0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 32, 32, 144)          3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 32, 32, 144)          576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 32, 32, 144)          0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 33, 33, 144)          0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 16, 16, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 16, 16, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 16, 16, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 16, 16, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 16, 16, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 16, 16, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 16, 16, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 16, 16, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 16, 16, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 16, 16, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 16, 16, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 16, 16, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 16, 16, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 16, 16, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 16, 16, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 16, 16, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 16, 16, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 16, 16, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 16, 16, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 16, 16, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 16, 16, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 16, 16, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 16, 16, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 16, 16, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 16, 16, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 16, 16, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 17, 17, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 8, 8, 192)            1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 8, 8, 192)            768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 8, 8, 192)            0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 8, 8, 64)             12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 8, 8, 64)             256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 8, 8, 384)            24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 8, 8, 384)            1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 8, 8, 384)            0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 8, 8, 384)            3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 8, 8, 384)            1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 8, 8, 384)            0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 8, 8, 64)             24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 8, 8, 64)             256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 8, 8, 64)             0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 8, 8, 384)            24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 8, 8, 384)            1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 8, 8, 384)            0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 8, 8, 384)            3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 8, 8, 384)            1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 8, 8, 384)            0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 8, 8, 64)             24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 8, 8, 64)             256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 8, 8, 64)             0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 8, 8, 384)            24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 8, 8, 384)            1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 8, 8, 384)            0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 8, 8, 384)            3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 8, 8, 384)            1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 8, 8, 384)            0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 8, 8, 64)             24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 8, 8, 64)             256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 8, 8, 64)             0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 8, 8, 384)            24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 8, 8, 384)            1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 8, 8, 384)            0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 8, 8, 384)            3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 8, 8, 384)            1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 8, 8, 384)            0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 8, 8, 96)             36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 8, 8, 96)             384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 8, 8, 576)            55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 8, 8, 576)            2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 8, 8, 576)            0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 8, 8, 576)            5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 8, 8, 576)            2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 8, 8, 576)            0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 8, 8, 96)             55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 8, 8, 96)             384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 8, 8, 96)             0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 8, 8, 576)            55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 8, 8, 576)            2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 8, 8, 576)            0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 8, 8, 576)            5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 8, 8, 576)            2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 8, 8, 576)            0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 8, 8, 96)             55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 8, 8, 96)             384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 8, 8, 96)             0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 8, 8, 576)            55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 8, 8, 576)            2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 8, 8, 576)            0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 9, 9, 576)            0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 4, 4, 576)            5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 4, 4, 576)            2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 4, 4, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 4, 4, 160)            92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 4, 4, 160)            640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 4, 4, 960)            153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 4, 4, 960)            3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 4, 4, 960)            0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 4, 4, 960)            8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 4, 4, 960)            3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 4, 4, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 4, 4, 160)            153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 4, 4, 160)            640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 4, 4, 160)            0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 4, 4, 960)            153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 4, 4, 960)            3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 4, 4, 960)            0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 4, 4, 960)            8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 4, 4, 960)            3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 4, 4, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 4, 4, 160)            153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 4, 4, 160)            640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 4, 4, 160)            0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 4, 4, 960)            153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 4, 4, 960)            3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 4, 4, 960)            0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 4, 4, 960)            8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 4, 4, 960)            3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 4, 4, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 4, 4, 320)            307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 4, 4, 320)            1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 4, 4, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 4, 4, 1280)           5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 4, 4, 1280)           0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 20480)                0         ['out_relu[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 20480)                0         ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 41)                   839721    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3097705 (11.82 MB)\n",
      "Trainable params: 839721 (3.20 MB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = tf.keras.layers.Flatten(name=\"flatten\")(last_output)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "#x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(41, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(pre_trained_model.input, x)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_lr = 1e-4\n",
    "num_epochs = 200\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=int_lr)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy')>0.9 and logs.get('accuracy')>0.9):\n",
    "      print('accuracy and validation accuracy reach 90%')\n",
    "      self.model.stop_training = True\n",
    "\n",
    "mycallback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "194/194 [==============================] - 129s 638ms/step - loss: 3.9602 - accuracy: 0.2234 - val_loss: 2.3184 - val_accuracy: 0.4466\n",
      "Epoch 2/1000\n",
      "194/194 [==============================] - 118s 606ms/step - loss: 2.8340 - accuracy: 0.3764 - val_loss: 2.0656 - val_accuracy: 0.5056\n",
      "Epoch 3/1000\n",
      "194/194 [==============================] - 116s 599ms/step - loss: 2.5050 - accuracy: 0.4414 - val_loss: 1.9792 - val_accuracy: 0.5375\n",
      "Epoch 4/1000\n",
      "194/194 [==============================] - 126s 651ms/step - loss: 2.3617 - accuracy: 0.4649 - val_loss: 1.9618 - val_accuracy: 0.5461\n",
      "Epoch 5/1000\n",
      "194/194 [==============================] - 119s 615ms/step - loss: 2.2340 - accuracy: 0.4897 - val_loss: 2.0022 - val_accuracy: 0.5474\n",
      "Epoch 6/1000\n",
      "194/194 [==============================] - 118s 605ms/step - loss: 2.1495 - accuracy: 0.5052 - val_loss: 1.9970 - val_accuracy: 0.5654\n",
      "Epoch 7/1000\n",
      "194/194 [==============================] - 115s 595ms/step - loss: 2.0515 - accuracy: 0.5241 - val_loss: 2.0193 - val_accuracy: 0.5660\n",
      "Epoch 8/1000\n",
      "194/194 [==============================] - 116s 600ms/step - loss: 1.9079 - accuracy: 0.5460 - val_loss: 2.0100 - val_accuracy: 0.5693\n",
      "Epoch 9/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 1.8998 - accuracy: 0.5451 - val_loss: 2.0016 - val_accuracy: 0.5720\n",
      "Epoch 10/1000\n",
      "194/194 [==============================] - 116s 599ms/step - loss: 1.8647 - accuracy: 0.5561 - val_loss: 2.0007 - val_accuracy: 0.5654\n",
      "Epoch 11/1000\n",
      "194/194 [==============================] - 116s 600ms/step - loss: 1.7981 - accuracy: 0.5726 - val_loss: 2.1491 - val_accuracy: 0.5601\n",
      "Epoch 12/1000\n",
      "194/194 [==============================] - 117s 600ms/step - loss: 1.7214 - accuracy: 0.5749 - val_loss: 2.0543 - val_accuracy: 0.5627\n",
      "Epoch 13/1000\n",
      "194/194 [==============================] - 116s 596ms/step - loss: 1.7211 - accuracy: 0.5862 - val_loss: 2.0197 - val_accuracy: 0.5793\n",
      "Epoch 14/1000\n",
      "194/194 [==============================] - 115s 591ms/step - loss: 1.6717 - accuracy: 0.5946 - val_loss: 2.0623 - val_accuracy: 0.5667\n",
      "Epoch 15/1000\n",
      "194/194 [==============================] - 115s 592ms/step - loss: 1.6832 - accuracy: 0.5852 - val_loss: 2.0140 - val_accuracy: 0.5760\n",
      "Epoch 16/1000\n",
      "194/194 [==============================] - 116s 598ms/step - loss: 1.6242 - accuracy: 0.5993 - val_loss: 2.0146 - val_accuracy: 0.5873\n",
      "Epoch 17/1000\n",
      "194/194 [==============================] - 116s 597ms/step - loss: 1.5851 - accuracy: 0.6135 - val_loss: 2.0737 - val_accuracy: 0.5713\n",
      "Epoch 18/1000\n",
      "194/194 [==============================] - 116s 599ms/step - loss: 1.5483 - accuracy: 0.6245 - val_loss: 2.1121 - val_accuracy: 0.5601\n",
      "Epoch 19/1000\n",
      "194/194 [==============================] - 116s 600ms/step - loss: 1.5393 - accuracy: 0.6173 - val_loss: 2.0995 - val_accuracy: 0.5700\n",
      "Epoch 20/1000\n",
      "194/194 [==============================] - 116s 598ms/step - loss: 1.5214 - accuracy: 0.6219 - val_loss: 2.1052 - val_accuracy: 0.5707\n",
      "Epoch 21/1000\n",
      "194/194 [==============================] - 116s 596ms/step - loss: 1.4677 - accuracy: 0.6380 - val_loss: 2.1189 - val_accuracy: 0.5680\n",
      "Epoch 22/1000\n",
      "194/194 [==============================] - 115s 595ms/step - loss: 1.4590 - accuracy: 0.6345 - val_loss: 2.0751 - val_accuracy: 0.5766\n",
      "Epoch 23/1000\n",
      "194/194 [==============================] - 116s 596ms/step - loss: 1.4458 - accuracy: 0.6322 - val_loss: 2.1633 - val_accuracy: 0.5587\n",
      "Epoch 24/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 1.4074 - accuracy: 0.6424 - val_loss: 2.0651 - val_accuracy: 0.5886\n",
      "Epoch 25/1000\n",
      "194/194 [==============================] - 118s 610ms/step - loss: 1.4235 - accuracy: 0.6414 - val_loss: 2.2410 - val_accuracy: 0.5587\n",
      "Epoch 26/1000\n",
      "194/194 [==============================] - 126s 648ms/step - loss: 1.3939 - accuracy: 0.6518 - val_loss: 2.1152 - val_accuracy: 0.5720\n",
      "Epoch 27/1000\n",
      "194/194 [==============================] - 123s 636ms/step - loss: 1.3914 - accuracy: 0.6448 - val_loss: 2.1776 - val_accuracy: 0.5660\n",
      "Epoch 28/1000\n",
      "194/194 [==============================] - 125s 643ms/step - loss: 1.3725 - accuracy: 0.6516 - val_loss: 2.1775 - val_accuracy: 0.5747\n",
      "Epoch 29/1000\n",
      "194/194 [==============================] - 125s 644ms/step - loss: 1.3526 - accuracy: 0.6574 - val_loss: 2.1915 - val_accuracy: 0.5826\n",
      "Epoch 30/1000\n",
      "194/194 [==============================] - 125s 646ms/step - loss: 1.3111 - accuracy: 0.6653 - val_loss: 2.2367 - val_accuracy: 0.5674\n",
      "Epoch 31/1000\n",
      "194/194 [==============================] - 128s 660ms/step - loss: 1.3408 - accuracy: 0.6613 - val_loss: 2.0902 - val_accuracy: 0.6025\n",
      "Epoch 32/1000\n",
      "194/194 [==============================] - 128s 659ms/step - loss: 1.3544 - accuracy: 0.6561 - val_loss: 2.1346 - val_accuracy: 0.5853\n",
      "Epoch 33/1000\n",
      "194/194 [==============================] - 124s 640ms/step - loss: 1.2838 - accuracy: 0.6710 - val_loss: 2.1096 - val_accuracy: 0.5793\n",
      "Epoch 34/1000\n",
      "194/194 [==============================] - 124s 642ms/step - loss: 1.2820 - accuracy: 0.6749 - val_loss: 2.1262 - val_accuracy: 0.5912\n",
      "Epoch 35/1000\n",
      "194/194 [==============================] - 123s 635ms/step - loss: 1.2464 - accuracy: 0.6765 - val_loss: 2.2980 - val_accuracy: 0.5660\n",
      "Epoch 36/1000\n",
      "194/194 [==============================] - 135s 699ms/step - loss: 1.3036 - accuracy: 0.6736 - val_loss: 2.0782 - val_accuracy: 0.5965\n",
      "Epoch 37/1000\n",
      "194/194 [==============================] - 119s 614ms/step - loss: 1.2403 - accuracy: 0.6792 - val_loss: 2.1739 - val_accuracy: 0.5972\n",
      "Epoch 38/1000\n",
      "194/194 [==============================] - 121s 625ms/step - loss: 1.2733 - accuracy: 0.6719 - val_loss: 2.1111 - val_accuracy: 0.6098\n",
      "Epoch 39/1000\n",
      "194/194 [==============================] - 127s 655ms/step - loss: 1.2158 - accuracy: 0.6881 - val_loss: 2.2238 - val_accuracy: 0.5833\n",
      "Epoch 40/1000\n",
      "194/194 [==============================] - 129s 663ms/step - loss: 1.2478 - accuracy: 0.6765 - val_loss: 2.2204 - val_accuracy: 0.5833\n",
      "Epoch 41/1000\n",
      "194/194 [==============================] - 121s 622ms/step - loss: 1.2252 - accuracy: 0.6828 - val_loss: 2.2442 - val_accuracy: 0.5747\n",
      "Epoch 42/1000\n",
      "194/194 [==============================] - 120s 616ms/step - loss: 1.2369 - accuracy: 0.6841 - val_loss: 2.0875 - val_accuracy: 0.6098\n",
      "Epoch 43/1000\n",
      "194/194 [==============================] - 118s 610ms/step - loss: 1.1901 - accuracy: 0.6895 - val_loss: 2.2108 - val_accuracy: 0.5926\n",
      "Epoch 44/1000\n",
      "194/194 [==============================] - 122s 628ms/step - loss: 1.1702 - accuracy: 0.6921 - val_loss: 2.2327 - val_accuracy: 0.5800\n",
      "Epoch 45/1000\n",
      "194/194 [==============================] - 120s 616ms/step - loss: 1.2106 - accuracy: 0.6925 - val_loss: 2.3124 - val_accuracy: 0.5693\n",
      "Epoch 46/1000\n",
      "194/194 [==============================] - 96s 496ms/step - loss: 1.1864 - accuracy: 0.6967 - val_loss: 2.2991 - val_accuracy: 0.5747\n",
      "Epoch 47/1000\n",
      "194/194 [==============================] - 79s 409ms/step - loss: 1.2043 - accuracy: 0.6963 - val_loss: 2.2242 - val_accuracy: 0.5820\n",
      "Epoch 48/1000\n",
      "194/194 [==============================] - 81s 416ms/step - loss: 1.1312 - accuracy: 0.7094 - val_loss: 2.3247 - val_accuracy: 0.5866\n",
      "Epoch 49/1000\n",
      "194/194 [==============================] - 79s 410ms/step - loss: 1.1856 - accuracy: 0.6947 - val_loss: 2.2459 - val_accuracy: 0.5813\n",
      "Epoch 50/1000\n",
      "194/194 [==============================] - 78s 403ms/step - loss: 1.1270 - accuracy: 0.6981 - val_loss: 2.2321 - val_accuracy: 0.5833\n",
      "Epoch 51/1000\n",
      "194/194 [==============================] - 78s 401ms/step - loss: 1.1394 - accuracy: 0.6944 - val_loss: 2.3094 - val_accuracy: 0.5753\n",
      "Epoch 52/1000\n",
      "194/194 [==============================] - 78s 404ms/step - loss: 1.1797 - accuracy: 0.6970 - val_loss: 2.3751 - val_accuracy: 0.5647\n",
      "Epoch 53/1000\n",
      "194/194 [==============================] - 86s 443ms/step - loss: 1.1117 - accuracy: 0.7083 - val_loss: 2.2841 - val_accuracy: 0.5800\n",
      "Epoch 54/1000\n",
      "194/194 [==============================] - 84s 431ms/step - loss: 1.1277 - accuracy: 0.6994 - val_loss: 2.3166 - val_accuracy: 0.5992\n",
      "Epoch 55/1000\n",
      "194/194 [==============================] - 83s 430ms/step - loss: 1.1184 - accuracy: 0.7030 - val_loss: 2.2922 - val_accuracy: 0.5773\n",
      "Epoch 56/1000\n",
      "194/194 [==============================] - 81s 420ms/step - loss: 1.1391 - accuracy: 0.7057 - val_loss: 2.3684 - val_accuracy: 0.5760\n",
      "Epoch 57/1000\n",
      "194/194 [==============================] - 89s 457ms/step - loss: 1.1690 - accuracy: 0.6971 - val_loss: 2.3079 - val_accuracy: 0.5859\n",
      "Epoch 58/1000\n",
      "194/194 [==============================] - 85s 438ms/step - loss: 1.1175 - accuracy: 0.7084 - val_loss: 2.2712 - val_accuracy: 0.5886\n",
      "Epoch 59/1000\n",
      "194/194 [==============================] - 83s 428ms/step - loss: 1.1630 - accuracy: 0.7039 - val_loss: 2.2633 - val_accuracy: 0.6012\n",
      "Epoch 60/1000\n",
      "194/194 [==============================] - 86s 442ms/step - loss: 1.0775 - accuracy: 0.7162 - val_loss: 2.4367 - val_accuracy: 0.5766\n",
      "Epoch 61/1000\n",
      "194/194 [==============================] - 85s 440ms/step - loss: 1.0830 - accuracy: 0.7144 - val_loss: 2.3609 - val_accuracy: 0.5780\n",
      "Epoch 62/1000\n",
      "194/194 [==============================] - 87s 448ms/step - loss: 1.0857 - accuracy: 0.7162 - val_loss: 2.3371 - val_accuracy: 0.5833\n",
      "Epoch 63/1000\n",
      "194/194 [==============================] - 85s 440ms/step - loss: 1.0893 - accuracy: 0.7128 - val_loss: 2.3393 - val_accuracy: 0.5846\n",
      "Epoch 64/1000\n",
      "194/194 [==============================] - 85s 438ms/step - loss: 1.0479 - accuracy: 0.7194 - val_loss: 2.4042 - val_accuracy: 0.5747\n",
      "Epoch 65/1000\n",
      "194/194 [==============================] - 87s 447ms/step - loss: 1.1199 - accuracy: 0.7180 - val_loss: 2.3677 - val_accuracy: 0.5859\n",
      "Epoch 66/1000\n",
      "194/194 [==============================] - 88s 452ms/step - loss: 1.0588 - accuracy: 0.7202 - val_loss: 2.3506 - val_accuracy: 0.5853\n",
      "Epoch 67/1000\n",
      "194/194 [==============================] - 90s 466ms/step - loss: 1.0731 - accuracy: 0.7185 - val_loss: 2.3917 - val_accuracy: 0.5912\n",
      "Epoch 68/1000\n",
      "194/194 [==============================] - 86s 444ms/step - loss: 1.0752 - accuracy: 0.7185 - val_loss: 2.3256 - val_accuracy: 0.6012\n",
      "Epoch 69/1000\n",
      "194/194 [==============================] - 91s 466ms/step - loss: 1.0747 - accuracy: 0.7143 - val_loss: 2.4561 - val_accuracy: 0.5786\n",
      "Epoch 70/1000\n",
      "194/194 [==============================] - 88s 456ms/step - loss: 1.0716 - accuracy: 0.7236 - val_loss: 2.3936 - val_accuracy: 0.5820\n",
      "Epoch 71/1000\n",
      "194/194 [==============================] - 87s 448ms/step - loss: 1.0695 - accuracy: 0.7191 - val_loss: 2.5401 - val_accuracy: 0.5660\n",
      "Epoch 72/1000\n",
      "194/194 [==============================] - 87s 448ms/step - loss: 1.0614 - accuracy: 0.7238 - val_loss: 2.4379 - val_accuracy: 0.5846\n",
      "Epoch 73/1000\n",
      "194/194 [==============================] - 84s 433ms/step - loss: 1.0853 - accuracy: 0.7175 - val_loss: 2.4399 - val_accuracy: 0.5614\n",
      "Epoch 74/1000\n",
      "194/194 [==============================] - 85s 440ms/step - loss: 1.0073 - accuracy: 0.7333 - val_loss: 2.5072 - val_accuracy: 0.5587\n",
      "Epoch 75/1000\n",
      "194/194 [==============================] - 90s 465ms/step - loss: 1.0312 - accuracy: 0.7348 - val_loss: 2.5358 - val_accuracy: 0.5634\n",
      "Epoch 76/1000\n",
      "194/194 [==============================] - 86s 441ms/step - loss: 1.0137 - accuracy: 0.7341 - val_loss: 2.4944 - val_accuracy: 0.5674\n",
      "Epoch 77/1000\n",
      "194/194 [==============================] - 81s 419ms/step - loss: 1.0417 - accuracy: 0.7359 - val_loss: 2.3604 - val_accuracy: 0.5839\n",
      "Epoch 78/1000\n",
      "194/194 [==============================] - 79s 409ms/step - loss: 1.0747 - accuracy: 0.7160 - val_loss: 2.5073 - val_accuracy: 0.5700\n",
      "Epoch 79/1000\n",
      "194/194 [==============================] - 82s 423ms/step - loss: 1.0450 - accuracy: 0.7315 - val_loss: 2.3096 - val_accuracy: 0.5972\n",
      "Epoch 80/1000\n",
      "194/194 [==============================] - 81s 417ms/step - loss: 1.0222 - accuracy: 0.7293 - val_loss: 2.4780 - val_accuracy: 0.5813\n",
      "Epoch 81/1000\n",
      "194/194 [==============================] - 84s 434ms/step - loss: 1.0380 - accuracy: 0.7351 - val_loss: 2.3961 - val_accuracy: 0.5906\n",
      "Epoch 82/1000\n",
      "194/194 [==============================] - 85s 440ms/step - loss: 1.0040 - accuracy: 0.7393 - val_loss: 2.4339 - val_accuracy: 0.5873\n",
      "Epoch 83/1000\n",
      "194/194 [==============================] - 82s 421ms/step - loss: 1.0316 - accuracy: 0.7314 - val_loss: 2.5110 - val_accuracy: 0.5826\n",
      "Epoch 84/1000\n",
      "194/194 [==============================] - 89s 460ms/step - loss: 1.0268 - accuracy: 0.7378 - val_loss: 2.4824 - val_accuracy: 0.5813\n",
      "Epoch 85/1000\n",
      "194/194 [==============================] - 80s 414ms/step - loss: 1.0063 - accuracy: 0.7395 - val_loss: 2.5337 - val_accuracy: 0.5833\n",
      "Epoch 86/1000\n",
      "194/194 [==============================] - 87s 447ms/step - loss: 1.0289 - accuracy: 0.7338 - val_loss: 2.5623 - val_accuracy: 0.5687\n",
      "Epoch 87/1000\n",
      "194/194 [==============================] - 87s 450ms/step - loss: 1.0340 - accuracy: 0.7393 - val_loss: 2.5148 - val_accuracy: 0.5766\n",
      "Epoch 88/1000\n",
      "194/194 [==============================] - 86s 441ms/step - loss: 1.0483 - accuracy: 0.7311 - val_loss: 2.5774 - val_accuracy: 0.5786\n",
      "Epoch 89/1000\n",
      "194/194 [==============================] - 92s 473ms/step - loss: 1.0095 - accuracy: 0.7414 - val_loss: 2.5625 - val_accuracy: 0.5693\n",
      "Epoch 90/1000\n",
      "194/194 [==============================] - 79s 409ms/step - loss: 0.9912 - accuracy: 0.7393 - val_loss: 2.5442 - val_accuracy: 0.5766\n",
      "Epoch 91/1000\n",
      "194/194 [==============================] - 79s 406ms/step - loss: 1.0083 - accuracy: 0.7341 - val_loss: 2.5598 - val_accuracy: 0.5647\n",
      "Epoch 92/1000\n",
      "194/194 [==============================] - 86s 442ms/step - loss: 1.0328 - accuracy: 0.7336 - val_loss: 2.4196 - val_accuracy: 0.5839\n",
      "Epoch 93/1000\n",
      "194/194 [==============================] - 80s 411ms/step - loss: 0.9783 - accuracy: 0.7462 - val_loss: 2.5448 - val_accuracy: 0.5806\n",
      "Epoch 94/1000\n",
      "194/194 [==============================] - 81s 416ms/step - loss: 1.0033 - accuracy: 0.7474 - val_loss: 2.5720 - val_accuracy: 0.5614\n",
      "Epoch 95/1000\n",
      "194/194 [==============================] - 89s 456ms/step - loss: 1.0047 - accuracy: 0.7393 - val_loss: 2.4305 - val_accuracy: 0.5853\n",
      "Epoch 96/1000\n",
      "194/194 [==============================] - 85s 440ms/step - loss: 1.0046 - accuracy: 0.7422 - val_loss: 2.4760 - val_accuracy: 0.5813\n",
      "Epoch 97/1000\n",
      "194/194 [==============================] - 87s 447ms/step - loss: 0.9873 - accuracy: 0.7480 - val_loss: 2.5777 - val_accuracy: 0.5780\n",
      "Epoch 98/1000\n",
      "194/194 [==============================] - 80s 411ms/step - loss: 1.0067 - accuracy: 0.7471 - val_loss: 2.4996 - val_accuracy: 0.5912\n",
      "Epoch 99/1000\n",
      "194/194 [==============================] - 86s 441ms/step - loss: 0.9622 - accuracy: 0.7450 - val_loss: 2.4619 - val_accuracy: 0.5959\n",
      "Epoch 100/1000\n",
      "194/194 [==============================] - 89s 456ms/step - loss: 1.0010 - accuracy: 0.7451 - val_loss: 2.5504 - val_accuracy: 0.5700\n",
      "Epoch 101/1000\n",
      "194/194 [==============================] - 79s 408ms/step - loss: 0.9725 - accuracy: 0.7438 - val_loss: 2.5905 - val_accuracy: 0.5873\n",
      "Epoch 102/1000\n",
      "194/194 [==============================] - 78s 402ms/step - loss: 0.9970 - accuracy: 0.7466 - val_loss: 2.4726 - val_accuracy: 0.5873\n",
      "Epoch 103/1000\n",
      "194/194 [==============================] - 78s 404ms/step - loss: 0.9958 - accuracy: 0.7474 - val_loss: 2.5837 - val_accuracy: 0.5753\n",
      "Epoch 104/1000\n",
      "194/194 [==============================] - 88s 453ms/step - loss: 0.9896 - accuracy: 0.7417 - val_loss: 2.5240 - val_accuracy: 0.5846\n",
      "Epoch 105/1000\n",
      "194/194 [==============================] - 82s 422ms/step - loss: 0.9703 - accuracy: 0.7477 - val_loss: 2.6534 - val_accuracy: 0.5760\n",
      "Epoch 106/1000\n",
      "194/194 [==============================] - 80s 411ms/step - loss: 0.9829 - accuracy: 0.7480 - val_loss: 2.5632 - val_accuracy: 0.5740\n",
      "Epoch 107/1000\n",
      "194/194 [==============================] - 86s 443ms/step - loss: 0.9800 - accuracy: 0.7435 - val_loss: 2.6385 - val_accuracy: 0.5627\n",
      "Epoch 108/1000\n",
      "194/194 [==============================] - 81s 419ms/step - loss: 0.9629 - accuracy: 0.7555 - val_loss: 2.6232 - val_accuracy: 0.5806\n",
      "Epoch 109/1000\n",
      "194/194 [==============================] - 85s 438ms/step - loss: 1.0070 - accuracy: 0.7462 - val_loss: 2.5714 - val_accuracy: 0.5813\n",
      "Epoch 110/1000\n",
      "194/194 [==============================] - 111s 574ms/step - loss: 0.9633 - accuracy: 0.7488 - val_loss: 2.6849 - val_accuracy: 0.5727\n",
      "Epoch 111/1000\n",
      "194/194 [==============================] - 88s 450ms/step - loss: 0.9527 - accuracy: 0.7553 - val_loss: 2.5866 - val_accuracy: 0.5899\n",
      "Epoch 112/1000\n",
      "194/194 [==============================] - 83s 427ms/step - loss: 0.9796 - accuracy: 0.7488 - val_loss: 2.5452 - val_accuracy: 0.5912\n",
      "Epoch 113/1000\n",
      "194/194 [==============================] - 92s 476ms/step - loss: 0.9568 - accuracy: 0.7483 - val_loss: 2.5992 - val_accuracy: 0.5747\n",
      "Epoch 114/1000\n",
      "194/194 [==============================] - 97s 502ms/step - loss: 0.9557 - accuracy: 0.7527 - val_loss: 2.5997 - val_accuracy: 0.5800\n",
      "Epoch 115/1000\n",
      "194/194 [==============================] - 85s 435ms/step - loss: 0.9560 - accuracy: 0.7550 - val_loss: 2.5584 - val_accuracy: 0.5820\n",
      "Epoch 116/1000\n",
      "194/194 [==============================] - 82s 421ms/step - loss: 1.0006 - accuracy: 0.7479 - val_loss: 2.5672 - val_accuracy: 0.5846\n",
      "Epoch 117/1000\n",
      "194/194 [==============================] - 83s 426ms/step - loss: 0.9632 - accuracy: 0.7574 - val_loss: 2.6106 - val_accuracy: 0.6045\n",
      "Epoch 118/1000\n",
      "194/194 [==============================] - 86s 446ms/step - loss: 0.9840 - accuracy: 0.7495 - val_loss: 2.6687 - val_accuracy: 0.5727\n",
      "Epoch 119/1000\n",
      "194/194 [==============================] - 85s 436ms/step - loss: 0.9444 - accuracy: 0.7571 - val_loss: 2.6700 - val_accuracy: 0.5720\n",
      "Epoch 120/1000\n",
      "194/194 [==============================] - 87s 448ms/step - loss: 0.9539 - accuracy: 0.7517 - val_loss: 2.4651 - val_accuracy: 0.6012\n",
      "Epoch 121/1000\n",
      "194/194 [==============================] - 82s 421ms/step - loss: 0.9475 - accuracy: 0.7488 - val_loss: 2.6047 - val_accuracy: 0.5839\n",
      "Epoch 122/1000\n",
      "194/194 [==============================] - 79s 408ms/step - loss: 0.9733 - accuracy: 0.7571 - val_loss: 2.6966 - val_accuracy: 0.5720\n",
      "Epoch 123/1000\n",
      "194/194 [==============================] - 82s 421ms/step - loss: 0.9418 - accuracy: 0.7532 - val_loss: 2.6561 - val_accuracy: 0.5747\n",
      "Epoch 124/1000\n",
      "194/194 [==============================] - 83s 430ms/step - loss: 0.9748 - accuracy: 0.7517 - val_loss: 2.7470 - val_accuracy: 0.5667\n",
      "Epoch 125/1000\n",
      "194/194 [==============================] - 117s 606ms/step - loss: 0.9748 - accuracy: 0.7584 - val_loss: 2.5990 - val_accuracy: 0.5879\n",
      "Epoch 126/1000\n",
      "194/194 [==============================] - 121s 624ms/step - loss: 0.9696 - accuracy: 0.7585 - val_loss: 2.6519 - val_accuracy: 0.5839\n",
      "Epoch 127/1000\n",
      "194/194 [==============================] - 121s 626ms/step - loss: 0.9251 - accuracy: 0.7613 - val_loss: 2.6782 - val_accuracy: 0.5932\n",
      "Epoch 128/1000\n",
      "194/194 [==============================] - 121s 621ms/step - loss: 0.9581 - accuracy: 0.7513 - val_loss: 2.6974 - val_accuracy: 0.5873\n",
      "Epoch 129/1000\n",
      "194/194 [==============================] - 119s 612ms/step - loss: 0.9893 - accuracy: 0.7496 - val_loss: 2.6874 - val_accuracy: 0.5873\n",
      "Epoch 130/1000\n",
      "194/194 [==============================] - 118s 609ms/step - loss: 0.9306 - accuracy: 0.7618 - val_loss: 2.6887 - val_accuracy: 0.5879\n",
      "Epoch 131/1000\n",
      "194/194 [==============================] - 120s 618ms/step - loss: 0.9498 - accuracy: 0.7577 - val_loss: 2.5567 - val_accuracy: 0.5919\n",
      "Epoch 132/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9493 - accuracy: 0.7635 - val_loss: 2.5275 - val_accuracy: 0.5965\n",
      "Epoch 133/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9300 - accuracy: 0.7682 - val_loss: 2.6807 - val_accuracy: 0.5800\n",
      "Epoch 134/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9072 - accuracy: 0.7658 - val_loss: 2.6495 - val_accuracy: 0.5793\n",
      "Epoch 135/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.9592 - accuracy: 0.7643 - val_loss: 2.7251 - val_accuracy: 0.5873\n",
      "Epoch 136/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9414 - accuracy: 0.7574 - val_loss: 2.6157 - val_accuracy: 0.5859\n",
      "Epoch 137/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.9297 - accuracy: 0.7538 - val_loss: 2.6988 - val_accuracy: 0.5674\n",
      "Epoch 138/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9166 - accuracy: 0.7677 - val_loss: 2.6654 - val_accuracy: 0.5893\n",
      "Epoch 139/1000\n",
      "194/194 [==============================] - 118s 606ms/step - loss: 0.9581 - accuracy: 0.7553 - val_loss: 2.7249 - val_accuracy: 0.5886\n",
      "Epoch 140/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.9418 - accuracy: 0.7629 - val_loss: 2.6355 - val_accuracy: 0.5939\n",
      "Epoch 141/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9497 - accuracy: 0.7603 - val_loss: 2.7152 - val_accuracy: 0.5780\n",
      "Epoch 142/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9431 - accuracy: 0.7626 - val_loss: 2.7461 - val_accuracy: 0.5820\n",
      "Epoch 143/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9093 - accuracy: 0.7658 - val_loss: 2.6384 - val_accuracy: 0.5965\n",
      "Epoch 144/1000\n",
      "194/194 [==============================] - 116s 601ms/step - loss: 0.9228 - accuracy: 0.7619 - val_loss: 2.6726 - val_accuracy: 0.5866\n",
      "Epoch 145/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.9717 - accuracy: 0.7548 - val_loss: 2.7341 - val_accuracy: 0.5839\n",
      "Epoch 146/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.8889 - accuracy: 0.7647 - val_loss: 2.6707 - val_accuracy: 0.6012\n",
      "Epoch 147/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9319 - accuracy: 0.7668 - val_loss: 2.7961 - val_accuracy: 0.5839\n",
      "Epoch 148/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9474 - accuracy: 0.7579 - val_loss: 2.7487 - val_accuracy: 0.5926\n",
      "Epoch 149/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9437 - accuracy: 0.7666 - val_loss: 2.7549 - val_accuracy: 0.5946\n",
      "Epoch 150/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.9210 - accuracy: 0.7674 - val_loss: 2.6510 - val_accuracy: 0.5999\n",
      "Epoch 151/1000\n",
      "194/194 [==============================] - 116s 600ms/step - loss: 0.9464 - accuracy: 0.7648 - val_loss: 2.7388 - val_accuracy: 0.5846\n",
      "Epoch 152/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9505 - accuracy: 0.7697 - val_loss: 2.7330 - val_accuracy: 0.6065\n",
      "Epoch 153/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9657 - accuracy: 0.7584 - val_loss: 2.6285 - val_accuracy: 0.5932\n",
      "Epoch 154/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9674 - accuracy: 0.7613 - val_loss: 2.7000 - val_accuracy: 0.5780\n",
      "Epoch 155/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9096 - accuracy: 0.7632 - val_loss: 2.8033 - val_accuracy: 0.5740\n",
      "Epoch 156/1000\n",
      "194/194 [==============================] - 118s 606ms/step - loss: 0.9380 - accuracy: 0.7660 - val_loss: 2.7589 - val_accuracy: 0.5720\n",
      "Epoch 157/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9724 - accuracy: 0.7605 - val_loss: 2.7864 - val_accuracy: 0.5826\n",
      "Epoch 158/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9428 - accuracy: 0.7685 - val_loss: 2.7206 - val_accuracy: 0.5820\n",
      "Epoch 159/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9076 - accuracy: 0.7689 - val_loss: 2.6986 - val_accuracy: 0.5926\n",
      "Epoch 160/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.9131 - accuracy: 0.7687 - val_loss: 2.7903 - val_accuracy: 0.5912\n",
      "Epoch 161/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.8988 - accuracy: 0.7690 - val_loss: 2.8032 - val_accuracy: 0.5707\n",
      "Epoch 162/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9590 - accuracy: 0.7643 - val_loss: 2.7551 - val_accuracy: 0.5773\n",
      "Epoch 163/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9109 - accuracy: 0.7723 - val_loss: 2.6861 - val_accuracy: 0.5926\n",
      "Epoch 164/1000\n",
      "194/194 [==============================] - 119s 614ms/step - loss: 0.9564 - accuracy: 0.7671 - val_loss: 2.7246 - val_accuracy: 0.5846\n",
      "Epoch 165/1000\n",
      "194/194 [==============================] - 117s 605ms/step - loss: 0.9596 - accuracy: 0.7681 - val_loss: 2.7547 - val_accuracy: 0.5853\n",
      "Epoch 166/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9369 - accuracy: 0.7655 - val_loss: 2.6463 - val_accuracy: 0.5873\n",
      "Epoch 167/1000\n",
      "194/194 [==============================] - 116s 600ms/step - loss: 0.9089 - accuracy: 0.7635 - val_loss: 2.8249 - val_accuracy: 0.5753\n",
      "Epoch 168/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9144 - accuracy: 0.7653 - val_loss: 2.8611 - val_accuracy: 0.5886\n",
      "Epoch 169/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.9127 - accuracy: 0.7732 - val_loss: 2.7171 - val_accuracy: 0.5899\n",
      "Epoch 170/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.8717 - accuracy: 0.7763 - val_loss: 2.7728 - val_accuracy: 0.5773\n",
      "Epoch 171/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.8893 - accuracy: 0.7745 - val_loss: 2.7399 - val_accuracy: 0.5853\n",
      "Epoch 172/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9019 - accuracy: 0.7716 - val_loss: 2.8581 - val_accuracy: 0.5773\n",
      "Epoch 173/1000\n",
      "194/194 [==============================] - 119s 613ms/step - loss: 0.9369 - accuracy: 0.7622 - val_loss: 2.8593 - val_accuracy: 0.5654\n",
      "Epoch 174/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9353 - accuracy: 0.7671 - val_loss: 2.6952 - val_accuracy: 0.5899\n",
      "Epoch 175/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9271 - accuracy: 0.7697 - val_loss: 2.7879 - val_accuracy: 0.5886\n",
      "Epoch 176/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9183 - accuracy: 0.7676 - val_loss: 2.7146 - val_accuracy: 0.5846\n",
      "Epoch 177/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9232 - accuracy: 0.7693 - val_loss: 2.8605 - val_accuracy: 0.5932\n",
      "Epoch 178/1000\n",
      "194/194 [==============================] - 117s 605ms/step - loss: 0.9268 - accuracy: 0.7679 - val_loss: 2.9723 - val_accuracy: 0.5601\n",
      "Epoch 179/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.8952 - accuracy: 0.7758 - val_loss: 2.7659 - val_accuracy: 0.5959\n",
      "Epoch 180/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.8862 - accuracy: 0.7815 - val_loss: 2.9650 - val_accuracy: 0.5793\n",
      "Epoch 181/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9389 - accuracy: 0.7655 - val_loss: 2.8840 - val_accuracy: 0.5926\n",
      "Epoch 182/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9290 - accuracy: 0.7716 - val_loss: 2.9085 - val_accuracy: 0.5786\n",
      "Epoch 183/1000\n",
      "194/194 [==============================] - 116s 600ms/step - loss: 0.9301 - accuracy: 0.7647 - val_loss: 2.8150 - val_accuracy: 0.5906\n",
      "Epoch 184/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9530 - accuracy: 0.7640 - val_loss: 2.9139 - val_accuracy: 0.5886\n",
      "Epoch 185/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.9382 - accuracy: 0.7697 - val_loss: 2.8818 - val_accuracy: 0.5820\n",
      "Epoch 186/1000\n",
      "194/194 [==============================] - 118s 607ms/step - loss: 0.9159 - accuracy: 0.7716 - val_loss: 2.8750 - val_accuracy: 0.5893\n",
      "Epoch 187/1000\n",
      "194/194 [==============================] - 116s 598ms/step - loss: 0.9074 - accuracy: 0.7687 - val_loss: 2.8043 - val_accuracy: 0.5846\n",
      "Epoch 188/1000\n",
      "194/194 [==============================] - 118s 606ms/step - loss: 0.8790 - accuracy: 0.7743 - val_loss: 2.8950 - val_accuracy: 0.5839\n",
      "Epoch 189/1000\n",
      "194/194 [==============================] - 117s 603ms/step - loss: 0.9275 - accuracy: 0.7700 - val_loss: 2.9323 - val_accuracy: 0.5853\n",
      "Epoch 190/1000\n",
      "194/194 [==============================] - 119s 616ms/step - loss: 0.9060 - accuracy: 0.7806 - val_loss: 3.0894 - val_accuracy: 0.5627\n",
      "Epoch 191/1000\n",
      "194/194 [==============================] - 118s 608ms/step - loss: 0.9015 - accuracy: 0.7803 - val_loss: 2.9143 - val_accuracy: 0.5720\n",
      "Epoch 192/1000\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.9326 - accuracy: 0.7702 - val_loss: 2.7576 - val_accuracy: 0.5866\n",
      "Epoch 193/1000\n",
      "194/194 [==============================] - 117s 602ms/step - loss: 0.9199 - accuracy: 0.7687 - val_loss: 2.9361 - val_accuracy: 0.5667\n",
      "Epoch 194/1000\n",
      "194/194 [==============================] - 118s 611ms/step - loss: 0.9465 - accuracy: 0.7734 - val_loss: 2.9556 - val_accuracy: 0.5800\n",
      "Epoch 195/1000\n",
      "194/194 [==============================] - 117s 601ms/step - loss: 0.8620 - accuracy: 0.7797 - val_loss: 2.8444 - val_accuracy: 0.5946\n",
      "Epoch 196/1000\n",
      "194/194 [==============================] - 120s 617ms/step - loss: 0.9144 - accuracy: 0.7753 - val_loss: 2.7697 - val_accuracy: 0.5992\n",
      "Epoch 197/1000\n",
      "194/194 [==============================] - 116s 598ms/step - loss: 0.9008 - accuracy: 0.7779 - val_loss: 2.8319 - val_accuracy: 0.5932\n",
      "Epoch 198/1000\n",
      "194/194 [==============================] - 120s 618ms/step - loss: 0.8948 - accuracy: 0.7734 - val_loss: 2.9147 - val_accuracy: 0.5919\n",
      "Epoch 199/1000\n",
      "194/194 [==============================] - 121s 622ms/step - loss: 0.8871 - accuracy: 0.7832 - val_loss: 2.8804 - val_accuracy: 0.5919\n",
      "Epoch 200/1000\n",
      "194/194 [==============================] - 122s 627ms/step - loss: 0.8851 - accuracy: 0.7871 - val_loss: 2.8033 - val_accuracy: 0.6052\n",
      "Epoch 201/1000\n",
      "194/194 [==============================] - 121s 624ms/step - loss: 0.8970 - accuracy: 0.7773 - val_loss: 2.8967 - val_accuracy: 0.5906\n",
      "Epoch 202/1000\n",
      "194/194 [==============================] - 243s 1s/step - loss: 0.9054 - accuracy: 0.7826 - val_loss: 2.8749 - val_accuracy: 0.5866\n",
      "Epoch 203/1000\n",
      "194/194 [==============================] - 81s 417ms/step - loss: 0.8773 - accuracy: 0.7718 - val_loss: 2.7825 - val_accuracy: 0.5952\n",
      "Epoch 204/1000\n",
      "194/194 [==============================] - 81s 419ms/step - loss: 0.9167 - accuracy: 0.7726 - val_loss: 2.8168 - val_accuracy: 0.5879\n",
      "Epoch 205/1000\n",
      "194/194 [==============================] - 83s 428ms/step - loss: 0.9007 - accuracy: 0.7800 - val_loss: 2.7344 - val_accuracy: 0.5906\n",
      "Epoch 206/1000\n",
      "194/194 [==============================] - 82s 423ms/step - loss: 0.9409 - accuracy: 0.7664 - val_loss: 2.8243 - val_accuracy: 0.5866\n",
      "Epoch 207/1000\n",
      "194/194 [==============================] - 82s 420ms/step - loss: 0.9054 - accuracy: 0.7785 - val_loss: 2.8840 - val_accuracy: 0.5866\n",
      "Epoch 208/1000\n",
      "194/194 [==============================] - 82s 420ms/step - loss: 0.8929 - accuracy: 0.7756 - val_loss: 3.0191 - val_accuracy: 0.5740\n",
      "Epoch 209/1000\n",
      "194/194 [==============================] - 79s 406ms/step - loss: 0.9167 - accuracy: 0.7752 - val_loss: 2.8824 - val_accuracy: 0.6019\n",
      "Epoch 210/1000\n",
      "194/194 [==============================] - 80s 411ms/step - loss: 0.9330 - accuracy: 0.7724 - val_loss: 2.9069 - val_accuracy: 0.5886\n",
      "Epoch 211/1000\n",
      "194/194 [==============================] - 78s 405ms/step - loss: 0.8934 - accuracy: 0.7813 - val_loss: 2.8912 - val_accuracy: 0.5912\n",
      "Epoch 212/1000\n",
      "194/194 [==============================] - 78s 403ms/step - loss: 0.9318 - accuracy: 0.7753 - val_loss: 2.9926 - val_accuracy: 0.5820\n",
      "Epoch 213/1000\n",
      "194/194 [==============================] - 79s 409ms/step - loss: 0.9113 - accuracy: 0.7706 - val_loss: 2.9121 - val_accuracy: 0.5820\n",
      "Epoch 214/1000\n",
      "194/194 [==============================] - 80s 410ms/step - loss: 0.9039 - accuracy: 0.7797 - val_loss: 2.8854 - val_accuracy: 0.5853\n",
      "Epoch 215/1000\n",
      "194/194 [==============================] - 79s 405ms/step - loss: 0.8945 - accuracy: 0.7837 - val_loss: 2.8865 - val_accuracy: 0.5932\n",
      "Epoch 216/1000\n",
      "194/194 [==============================] - 78s 404ms/step - loss: 0.9425 - accuracy: 0.7742 - val_loss: 3.0804 - val_accuracy: 0.5674\n",
      "Epoch 217/1000\n",
      "194/194 [==============================] - 78s 400ms/step - loss: 0.9142 - accuracy: 0.7750 - val_loss: 2.8625 - val_accuracy: 0.5886\n",
      "Epoch 218/1000\n",
      "194/194 [==============================] - 79s 405ms/step - loss: 0.9164 - accuracy: 0.7697 - val_loss: 2.9067 - val_accuracy: 0.5826\n",
      "Epoch 219/1000\n",
      "119/194 [=================>............] - ETA: 27s - loss: 0.9302 - accuracy: 0.7778"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmycallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "H = model.fit(train_generator,\n",
    "              epochs=num_epochs,\n",
    "              validation_data=validation_generator,\n",
    "              callbacks=mycallback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mggplot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, num_epochs), \u001b[43mH\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, num_epochs), H\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.arange(0, num_epochs), H.history[\"loss\"], label=\"training\")\n",
    "plt.plot(np.arange(0, num_epochs), H.history[\"val_loss\"], label=\"validation\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25c6f65c110>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.arange(0, num_epochs), H.history[\"accuracy\"], label=\"training\")\n",
    "plt.plot(np.arange(0, num_epochs), H.history[\"val_accuracy\"], label=\"validation\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights/weights_mobilenet-000/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model.save(os.path.join('models/h5', 'explorentt_mobilenet.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:root:Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs import converters\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs.converters.converter import convert\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 38, in <module>\n",
      "    from tensorflowjs.converters import tf_saved_model_conversion_v2\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\", line 28, in <module>\n",
      "    import tensorflow_decision_forests\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\__init__.py\", line 64, in <module>\n",
      "    from tensorflow_decision_forests import keras\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\keras\\__init__.py\", line 53, in <module>\n",
      "    from tensorflow_decision_forests.keras import core\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\keras\\core.py\", line 62, in <module>\n",
      "    from tensorflow_decision_forests.keras import core_inference\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\keras\\core_inference.py\", line 36, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference import api as tf_op\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\api.py\", line 179, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference import op\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op.py\", line 15, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference.op_dynamic import *\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py\", line 24, in <module>\n",
      "    raise e\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py\", line 21, in <module>\n",
      "    ops = tf.load_op_library(resource_loader.get_path_to_datafile(\"inference.so\"))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\load_library.py\", line 54, in load_op_library\n",
      "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format=keras models/h5/explorentt_1.h5 models/h5-tfjs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
